# -*- coding: utf-8 -*-
"""Anime-Rekomendasi-wandi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xMoj5_mvbCou8IcTFWxunxj3wRkF8UMc

# Anime Recommendation System

![istri_gw_bang](https://github.com/Mayumiwandi/My-Learn/assets/84662810/0c0453b2-e155-4219-b8fb-dd3d963f1718)

## Data Collection

Import Library
"""

from google.colab import files
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score

!pip install -q kaggle

files.upload()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

"""Anime Dataset 2023 [Unduh Datasets](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset/data?select=anime-filtered.csv)"""

!kaggle datasets download -d dbdmobile/myanimelist-dataset

!unzip /content/myanimelist-dataset.zip

"""Dapat kita lihat setelah kita Exstrak file zip, terdapat banyak file csv, tetapi pada kasus ini kita hanya menggunakan file `anime-filtered.csv`"""

df = pd.read_csv('/content/anime-filtered.csv')

"""## Data Understanding"""

df.head()

print(f'Terdapat  {df.shape[0]} Table dan {df.shape[1]} columns.')

for i, (nama_kolom, jumlah) in enumerate(df.count().items(), 1):
    print(f"Kolom {i:2d}: {nama_kolom} - Berjumlah:  {jumlah}")

df.info()

"""Dari output yang diberikan, dapat disimpulkan bahwa:

Terdapat total _25_ kolom dalam dataframe.  

- Dari _25_ kolom tersebut, terdapat _15_ kolom dengan tipe data `object`, yang kemungkinan besar merupakan fitur kategoris. Kolom-kolom tersebut adalah: *_Name, Genres, English name, Japanese name, sypnopsis, Type, Episodes, Aired, Premiered, Producers, Licensors, Studios, Source, Duration, dan Rating._*  

- Selanjutnya, terdapat _2_ kolom dengan tipe data `float64`, yang kemungkinan merupakan fitur numerik. Kolom-kolom tersebut adalah *_Score dan Ranked_*.  

- Ada _8_ kolom dengan tipe data `int64`, yang mungkin juga merupakan fitur numerik. Kolom-kolom ini adalah: *_anime_id, Popularity, Members, Favorites, Watching, Completed, On-Hold, dan Dropped_*.

# Tanda
Pada proyek ini, meskipun dataset menyediakan berbagai fitur, namun hanya tiga di antaranya yang akan dimanfaatkan untuk membangun model sistem rekomendasi yang sederhana, yaitu `Name`, `Score`, `Genres`,`Type`, dan `Studios`. Meskipun fitur-fitur lainnya mungkin memiliki nilai tambah untuk membangun model yang lebih kompleks, untuk keperluan proyek ini, hanya fitur-fitur tersebut yang akan difokuskan.

Dalam pembuatan model menggunakan _Content Based Filtering_, data yang diperlukan adalah nama anime `Name` dan Genre anime`Genres`. Sementara itu, untuk _Collaborative Filtering_, data yang diperlukan adalah nama anime `Name` dan Score yang diberikan pengguna `Score`.
"""

df.duplicated().sum()

"""Tidak terdapat data duplikat"""

df.isnull().sum()

"""## Exploratory Data Analysis

### Deskripsi Variabel
"""

df.columns

"""**Penjelasan Kolom Dataframe**

Kolom datasets anime memiliki informasi berikut:

* **`anime_id`:** ID unik untuk setiap anime (angka atau kode pengenal).
* **`Name`:** Judul anime dalam bahasa aslinya.
* **`Score`:** Skor atau rating yang diberikan kepada anime.
* **`Genres`:** Genre anime, dipisahkan dengan koma (misalnya, Aksi, Komedi, Fantasi).
* **`English name`:** Judul anime dalam bahasa Inggris (jika tersedia).
* **`Japanese name`:** Judul anime dalam bahasa Jepang (jika tersedia).
* **`Synopsis`:** Deskripsi singkat atau ringkasan plot anime.
* **`Type`:** Jenis anime (misalnya, TV Series, Movie, OVA, dll.).
* **`Episodes`:** Jumlah episode dalam anime.
* **`Aired`:** Tanggal penayangan anime.
* **`Premiered`:** Musim dan tahun penayangan perdana anime.
* **`Producers`:** Perusahaan produksi atau produser anime.
* **`Licensors`:** Pihak yang memiliki lisensi anime (misalnya, platform streaming).
* **`Studios`:** Studio animasi yang mengerjakan anime.
* **`Source`:** Sumber materi anime (misalnya, manga, light novel, original).
* **`Duration`:** Durasi setiap episode anime.
* **`Rating`:** Batasan usia untuk menonton anime.
* **`Ranked`:** Peringkat anime berdasarkan popularitas atau kriteria lain.
* **`Popularity`:** Peringkat popularitas anime.
* **`Members`:** Jumlah anggota yang telah menambahkan anime ke daftar mereka di platform.
* **`Favorites`:** Jumlah pengguna yang menandai anime sebagai favorit.
* **`Watching`:** Jumlah anime yang sedang ditonton oleh pengguna.
* **`Completed`:** Jumlah anime yang telah selesai ditonton oleh pengguna.
* **`On Hold`:** Jumlah anime yang ditunda oleh pengguna.
* **`Dropped`:** Jumlah anime yang dihentikan oleh pengguna.

### Visualisasi
"""

ona = df.loc[df['Type'] == 'ONA'].count()[0]
tv = df.loc[df['Type'] == 'TV'].count()[0]
movie = df.loc[df['Type'] == 'Movie'].count()[0]
music = df.loc[df['Type'] == 'Music'].count()[0]
special = df.loc[df['Type'] == 'Special'].count()[0]
ova = df.loc[df['Type'] == 'OVA'].count()[0]

labels = ['ONA', 'TV', 'Movie', 'Music', 'Special', 'OVA']
colors = ['#81F4E1', '#56CBF9', '#F5D491', '#BEB7A4', '#B4E1FF', '#F06C9B']

plt.figure(figsize = (10,7))
plt.title('Anime Categories Distribution')
plt.pie([ona, tv, movie, music, special, ova],
        labels = labels,
        colors = colors,
        autopct = '%.2f %%'
        )

plt.show()

plt.hist(df.Score, color='#B4E1FF', edgecolor='black')
plt.ylabel('Total')
plt.xlabel('Avg Rating')
plt.title("Anime's Average Ratings Distribution")
plt.show()

df.describe().T

df.sort_values(by='Members', ascending=False).head()

plt.figure(figsize = (20,15))
top10_anime = df[['Name', 'Members']].sort_values(by = 'Members',ascending = False).head(10)

colors = ['#87255B', '#56CBF9', '#F5D491', '#BEB7A4', '#B4E1FF', '#F06C9B', '#D3C4D1', '#81F4E1', '#C2AFF0', '#C57B57']


labels = top10_anime[['Name']].values.flatten()
values = top10_anime[['Members']].values.flatten()

plt.barh(labels, values, color = colors, edgecolor='black')
plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='x', alpha=0.7)
plt.xticks(fontsize = 15)
plt.yticks(fontsize = 15)
plt.title("Top 10 Anime Community", fontdict = {'fontsize' : 20})
plt.show()

plt.show()

df.sort_values(by='Score', ascending=False).head()

plt.figure(figsize = (20,15))
top10_anime = df[['Name', 'Score']].sort_values(by = 'Score',ascending = False).head(10)

colors = ['#87255B', '#56CBF9', '#F5D491', '#BEB7A4', '#B4E1FF', '#F06C9B', '#D3C4D1', '#81F4E1', '#C2AFF0', '#C57B57']


labels = top10_anime[['Name']].values.flatten()
values = top10_anime[['Score']].values.flatten()

plt.barh(labels, values, color = colors, edgecolor='black')
plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='x', alpha=0.7)
plt.xticks(fontsize = 15)
plt.yticks(fontsize = 15)
plt.title("Top 10 Anime Rating", fontdict = {'fontsize' : 20})
plt.show()

plt.show()

"""## Data Preparation"""

import re

def text_cleaning(text):
  text = re.sub(r"[^\w\s]", "", text)
  text = re.sub(r"https?://[^\s]+", "", text)
  return text

df['Name'] = df['Name'].apply(text_cleaning)

"""Menghapus tanda baca alfanumerik dan Hapus link (URL)"""

df

df.duplicated().sum()

"""Tidak terdapat data duplikat"""

df.isnull().sum()

"""Terdapat *Missing value* pada kolom `sypnopsis dan Ranked`"""

df = df.dropna()

"""Menghapus data *Missing value*"""

df.isnull().sum()

print(f'Terdapat  {df.shape[0]} Table dan {df.shape[1]} columns.')

"""Yang awalnya jumlah dataset sebanyak `14952` dan dengan menghapus jumlah *missing value* dataset sekarang menjadi `13229`."""

df.describe().T

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah). - 75% adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

## Model Development
"""

df

data = df.drop(columns=['anime_id',
                        'Episodes',
                        'English name',
                        'Japanese name',
                        'sypnopsis',
                        'Episodes',
                        'Aired',
                        'Premiered',
                        'Producers',
                        'Licensors',
                        'Source',
                        'Duration',
                        'Rating',
                        'Ranked',
                        'Popularity',
                        'Members',
                        'Favorites',
                        'Watching',
                        'Completed',
                        'On-Hold',
                        'Dropped'])

"""Mengahapus kolom yang tidak dibutuhkan pada model kali ini."""

data

"""### Model Content Based Filtering (dengan Filter Genres)"""

tfid = TfidfVectorizer()
tfid.fit(data['Genres'])

tfid.get_feature_names_out()

tfidf_matrix = tfid.fit_transform(data['Genres'])


tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfid.get_feature_names_out(),
    index=data.Genres
).sample(22, axis=1).sample(10, axis=0)

"""Output `matriks tf-idf` di atas menunjukkan hubungan antara nama anime terhadap kategori yang dipilih. Matriks ini menunjukkan seberapa besar korelasi antara Anime terhadap kategori yang dipilih."""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['Name'], columns=data['Name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(5, axis=0)

def anime_recommendations(anime_name, similarity_data=cosine_sim_df, items=data[['Name','Genres']], k=5):


    index = similarity_data.loc[:,anime_name].to_numpy().argpartition(
        range(-1, -k, -1))


    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(anime_name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

data[data.Name.eq('One Piece')]

anime_recommendations('One Piece')

"""Sistem telah berhasil merekomendasikan top 5 persen anime yang mirip dengan *One Piece*, yaitu beberapa film dan seri dari *One Piece* itu sendiri. Jadi, jika pengguna menyukai *One Piece*, maka sistem dapat merekomendasikan seri atau movie *One Piece* lainnya.

### Model K-Nearest Neighbor
"""

animedf_name = pd.DataFrame({'Name':data['Name']})
animedf_name.head()

data.set_index('Name',inplace=True)

data_n = data[['Score','Type','Studios']]

data_new = pd.get_dummies(data_n[['Type','Studios']])
data_new = pd.concat([data_n, data_new], axis=1)
data_new = data_new.drop(columns='Type')
data_new = data_new.drop(columns='Studios')
data_new.head()

model = NearestNeighbors(metric='euclidean')
model.fit(data_new)

def Recommended_model(anime_name:str, recommend_anime:int=5):
  print(f'Apabila pengguna menyukai aplikasi:{anime_name[0]} \nBerikut ini adalah aplikasi yang juga mungkin akan disukai :')
  distances, neighbors = model.kneighbors(data_new.loc[anime_name],n_neighbors=recommend_anime)
  similar_anime = []
  for anime_name in animedf_name.loc[neighbors[0][:]].values:
    similar_anime.append(anime_name[0])
  similar_distance = []
  for distance in distances[0]:
    similar_distance.append(f"{round(100-distance, 2)}%")
  return pd.DataFrame(data = {"Anime Name" : similar_anime, "Similiarity Score" : similar_distance})

Recommended_model(animedf_name.loc[21])

"""## Evaluation

### Calinski-Harabasz score

_**Calinski-Harabasz score**_ adalah metrik evaluasi untuk algoritme pengelompokan yang mengukur seberapa baik pengelompokan memisahkan data ke dalam kelompok-kelompok yang kompak dan terpisah. Didefinisikan sebagai rasio antara sebaran dalam cluster dan sebaran antar cluster, semakin tinggi nilai CH, semakin baik kinerja pengelompokan tersebut, tanpa memerlukan informasi tentang label kebenaran dasar.

Rumus  Calinski-Harabasz Score (CH) adalah:

$$CH = \frac{B}{W} \times \frac{N - k}{k - 1}$$

Di mana:
- \( B \) adalah sebaran antar cluster (between-cluster scatter).
- \( W \) adalah sebaran dalam cluster (within-cluster scatter).
- \( N \) adalah jumlah total data.
- \( k \) adalah jumlah cluster.
"""

ch_score = calinski_harabasz_score(data_new, animedf_name)

ch_score

"""Hasil evaluasi menunjukkan bahwa kluster dalam model ini masih belum terpisahkan dengan baik, yang tercermin dari nilai skor Calinski-Harabasz (CH) yang relatif rendah sebesar `3.1613291729405617`. Kondisi ini mengindikasikan adanya potensi untuk rekomendasi yang kurang sesuai pada beberapa aplikasi, yang mungkin tidak sepenuhnya sesuai dengan preferensi pengguna. Oleh karena itu, perlu dilakukan peninjauan lebih lanjut atau penyesuaian pada model untuk meningkatkan pemisahan kluster dan akurasi rekomendasi.

### Davies Bouldin Score

_**Davies Bouldin Score (DB)**_ adalah metrik evaluasi kinerja pengelompokan yang mengukur rata-rata kesamaan setiap cluster dengan cluster yang paling mirip dengan membandingkan jarak dalam cluster terhadap jarak antar cluster. Dengan skor minimum nol, semakin rendah nilai DB, semakin baik kinerja pengelompokannya, menunjukkan cluster yang lebih dekat satu sama lain dan kurang tersebar. Berbeda dari sebagian besar metrik, DB tidak memerlukan pengetahuan apriori tentang label kebenaran dasar, mirip dengan Silhouette Score, namun memiliki formulasi yang lebih sederhana, memberikan cara efisien untuk mengevaluasi pengelompokan tanpa memerlukan pengetahuan tambahan tentang struktur data.

Rumus Davies-Bouldin Score (DB) adalah:


$$ DB = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \left( \frac{R_i + R_j}{d(c_i, c_j)} \right) $$


Di mana:
- \( k \) adalah jumlah cluster.
- \( R_i \) adalah radius dalam cluster ke-i.
- \( d(c_i, c_j) \) adalah jarak antara pusat cluster ke-i (\( c_i \)) dan pusat cluster ke-j (\( c_j \)).

Davies-Bouldin didefinisikan sebagai rata-rata dari nilai-nilai R, di mana setiap nilai R adalah rasio antara jumlah dari radius dalam cluster (dalam pengertian jarak, misalnya Euclidean distance) dan jarak antara pusat cluster, dengan pusat-pusat yang lain. Rasio ini digunakan untuk mengevaluasi kemiripan setiap cluster dengan cluster lain.
"""

db_score = davies_bouldin_score(data_new, animedf_name)

db_score

"""Hasil evaluasi Davies-Bouldin (DB) menunjukkan bahwa model ini memiliki skor yang relatif cukup kecil, dengan nilai DB sebesar `0.7864266764751376` Hal ini menandakan bahwa model sudah memiliki separasi kluster yang cukup baik. Sebagai hasilnya, rekomendasi anime memiliki kualitas yang baik, mempertimbangkan bahwa pengelompokan kluster dalam model sudah cukup efektif dalam memisahkan data. Hal ini terbukti dengan hasil rekomendasi aplikasi yang sudah cukup baik."""